# -*- coding: utf-8 -*-
"""(Used) Golf_Class.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Co8ebznAnNP587-0wk8Dt-Pyt1vn7C9O
"""

# Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_score
from sklearn.metrics import ConfusionMatrixDisplay

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

# Baca Data
golf = pd.read_csv('golf_dataset.csv', low_memory=True)

"""# Data Understanding

Cek Informasi Dataset
"""

# Tampilkan informasi data
golf.info()

# Ringkasan tipe data
print("\nJumlah Tipe Data")
display(golf.dtypes.value_counts())

# Lihat dimensi data
print(f"\nJumlah baris: {golf.shape[0]}")
print(f"Jumlah kolom: {golf.shape[1]}")

# Lihat 5 baris pertama data
print("\nLihat 5 baris pertama data:")
golf.head()

"""Cek Duplicate Values"""

print("Jumlah baris duplikat:", golf.duplicated().sum())

"""Cek Missing Values"""

print("Jumlah nilai kosong:", golf.isna().sum())

"""Statistik Deskriptif"""

# Data Numerik
print("Deskriptif Statistik Numerik")
display(golf.select_dtypes(include=[np.number]).describe().T)

# Data Kategorik
print("\nDeskriptif Data Kategorik")
display(golf.select_dtypes(include=['object', 'category']).describe().T)

"""Lihat Cardinality Data Awal"""

cardinality = (golf.nunique() / len(golf)).sort_values(ascending=False)
lihat_cardinality = pd.DataFrame({'unique_count': golf.nunique(),
                    'cardinality_ratio': cardinality})

# Urutkan dari tertinggi
cek = lihat_cardinality.sort_values(by='cardinality_ratio', ascending=False)
print(cek)

"""# Data Preparation

Cek Distribusi Target
"""

target = ['Play']

for col in target:
  value_count = golf[col].value_counts(dropna=False)
  distribusi = golf[col].value_counts(normalize=True, dropna=False) * 100

  summary = pd.DataFrame({
    'Jumlah': value_count,
    'Distribusi (%)': distribusi.round(2)
  }).reset_index().rename(columns=({'index': 'Value'}))

  display(summary)

"""Deteksi Outlier (Boxplot)"""

outlier_columns = []

for col in outlier_columns:
  Q1 = golf[col].quantile(0.25)
  Q3 = golf[col].quantile(0.75)
  IQR = Q3 - Q1
  lower = Q1 - 1.5 * IQR
  upper = Q3 + 1.5 * IQR

  outlier_count = ((golf[col] < lower) | (golf[col] > upper)).sum()

  if outlier_count > 0:
    outlier_columns.append(col)

outlier_columns

"""Korelasi Fitur (Heatmap)"""

num_columns = golf.select_dtypes(include=['int64', 'float64'])

# Hitung korelasi
corr_matrix = num_columns.corr()

# Print correlation matrix
print(corr_matrix)

# Plot heatmap
plt.figure(figsize=(10,6))
sns.heatmap(corr_matrix, cmap="coolwarm", center=0, annot=True, fmt='.2f', linewidth=0.5)
plt.title("Korelasi antar Fitur Numerik")
plt.show()

"""Filter kolom tidak perlu"""

filter_col = ['Date', 'Review', 'PlayTimeHour', 'EmailCampaign', 'ID', 'MaintenanceTask']
golf_filtered = golf[[col for col in golf.columns if col not in filter_col]]

"""Exploratory Data Analysis (EDA)

Univariate Analysis
"""

# Tampilkan visualisasi data numerik
num_columns = golf_filtered.select_dtypes(include=np.number)

# Plotting
for col in num_columns:
    plt.figure(figsize=(6,4))
    plt.hist(golf_filtered[col].dropna())
    plt.title(f"Distribution of {col}")
    plt.xlabel(col)
    plt.ylabel("Frequency")
    plt.show()

# Identifikasi kolom kategorikal
cat_columns = golf_filtered.select_dtypes(include=['object']).columns

# Plot Categorical Data Distribution
for col in cat_columns:
    plt.figure(figsize=(6,4))
    golf_filtered[col].value_counts().plot(kind='bar')
    plt.title(f"Category Counts for {col}")
    plt.xlabel(col)
    plt.ylabel("Count")
    plt.xticks(rotation=45, ha='right')
    plt.show()

"""Data Preprocessing - Encoding Kolom Kategorikal"""

# Data Kategorik
print("\nDeskriptif Data Kategorik")
display(golf_filtered.select_dtypes(include=['object', 'category']).describe().T)

golf_filtered['Month'].unique()

golf_filtered['Season'].unique()

golf_filtered['Outlook'].unique()

"""One-Hot Encoding"""

# Kolom
cat_columns = ['Month', 'Season', 'Outlook', 'Weekday']

# pd.get_dummies()
golf_filtered = pd.get_dummies(golf_filtered, columns=cat_columns, dtype=int)

# df info after encoding
golf_filtered.info()

# display result
display(golf_filtered.head(10))

display(golf_filtered.select_dtypes(include=[np.number]).describe().T)

"""###Split Data"""

# Pisahkan target & fitur
X = golf_filtered.drop('Play', axis=1) # fitur
y = golf_filtered['Play'] # target

X.head()

y.head()

"""Cek proporsi target"""

# Cek proporsi target
golf_filtered['Play'].value_counts(normalize=True)

"""####Split Data 90:10"""

# Split data ke training and testing set
X1_train, X1_test, y1_train, y1_test = train_test_split(X, y, test_size=0.1, random_state=42)

print(f'Training set: {X1_train.shape}')
print(f'Testing set: {X1_test.shape}')

print('X1_train = ', len(X1_train))
print('X1_test = ', len(X1_test))
print('y1_train = ', len(y1_train))
print('y1_test = ', len(y1_test))

"""Feature Scaling"""

num_cols = ['Temperature', 'Humidity', 'Crowdedness']
num_features = [col for col in X1_train.columns if col not in num_cols]

# Inisialisasi
scaler = StandardScaler()

# Fit & transform kolom numerik pada data testing
X1_train_num = X1_train[num_cols]
X1_train_num_scaled = scaler.fit_transform(X1_train_num)
X1_train_num_scaled_df = pd.DataFrame(X1_train_num_scaled, columns=num_cols, index=X1_train_num.index)

# Transform kolom numerik pada data testing
X1_test_num = X1_test[num_cols]
X1_test_num_scaled = scaler.transform(X1_test_num)
X1_test_num_scaled_df = pd.DataFrame(X1_test_num_scaled, columns=num_cols, index=X1_test_num.index)

# Gabung kembali kolom
X1_train_final = pd.concat([X1_train_num_scaled_df, X1_train[num_features]], axis=1)
X1_test_final = pd.concat([X1_test_num_scaled_df, X1_test[num_features]], axis=1)

print("Training set final:", X1_train_final.shape)
print("Testing set final:", X1_test_final.shape)

# Cek jumlah dan nama kolom
print("Kolom Training:", X1_train_final.columns.tolist())
print("Kolom Testing:", X1_test_final.columns.tolist())

# Cek apakah data testing yang dimasukkan ke model sudah mengandung NaN
print("NaN di data testing input:", X1_test_final.isnull().sum().sum())

"""Resampling Target"""

# Resampling: SMOTE
smote = SMOTE(random_state=42)
X1_resampled, y1_resampled = smote.fit_resample(X1_train_final, y1_train)

# Cek kembali proporsi label
print("Sebelum SMOTE:")
print(y1_train.value_counts(normalize=True))

print("Sesudah SMOTE:")
print(y1_resampled.value_counts(normalize=True))

"""###Split Data 80:20"""

# Split data ke training and testing set
X2_train, X2_test, y2_train, y2_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Training set: {X2_train.shape}')
print(f'Testing set: {X2_test.shape}')

"""Feature Scaling"""

num_cols = ['Temperature', 'Humidity', 'Crowdedness']
num_features = [col for col in X2_train.columns if col not in num_cols]

# Inisialisasi
scaler = StandardScaler()

# Fit & transform kolom numerik pada data testing
X2_train_num = X2_train[num_cols]
X2_train_num_scaled = scaler.fit_transform(X2_train_num)
X2_train_num_scaled_df = pd.DataFrame(X2_train_num_scaled, columns=num_cols, index=X2_train_num.index)

# Transform kolom numerik pada data testing
X2_test_num = X2_test[num_cols]
X2_test_num_scaled = scaler.transform(X2_test_num)
X2_test_num_scaled_df = pd.DataFrame(X2_test_num_scaled, columns=num_cols, index=X2_test_num.index)

# Gabung kembali kolom
X2_train_final = pd.concat([X2_train_num_scaled_df, X2_train[num_features]], axis=1)
X2_test_final = pd.concat([X2_test_num_scaled_df, X2_test[num_features]], axis=1)

print("Training set final:", X2_train_final.shape)
print("Testing set final:", X2_test_final.shape)

# Cek jumlah dan nama kolom
print("Kolom Training:", X2_train_final.columns.tolist())
print("Jumlah Kolom Training:", X2_train_final.shape[1])
print("Kolom Testing:", X2_test_final.columns.tolist())
print("Jumlah Kolom Testing:", X2_test_final.shape[1])

# Cek apakah data testing yang dimasukkan ke model sudah mengandung NaN
print("NaN di data testing input:", X2_test_final.isnull().sum().sum())

"""Resampling Target"""

# Resampling: SMOTE
smote = SMOTE(random_state=42)
X2_resampled, y2_resampled = smote.fit_resample(X2_train_final, y2_train)

# Cek kembali proporsi label
print("Sebelum SMOTE:")
print(y2_train.value_counts(normalize=True))

print("Sesudah SMOTE:")
print(y2_resampled.value_counts(normalize=True))

"""# Data Modeling

Model 1: Naive Bayes

Split Data 90:10
"""

# 90:10 split data
nb1 = GaussianNB()
nb1.fit(X1_resampled, y1_resampled)

# Testing Data
nb1_pred = nb1.predict(X1_test_final)
nb1_proba_nb = nb1.predict_proba(X1_test_final)[:, 1]
print(nb1_pred)

y1data = pd.DataFrame()
y1data['y1_test'] = pd.DataFrame(y1_test)
y1data['nb1_pred'] = pd.DataFrame(nb1_pred)
y1data.head()

"""Split Data 80:20"""

# 80:20 split data resampling
nb2 = GaussianNB()
nb2.fit(X2_resampled, y2_resampled)

# Testing Resampling Data
nb2_pred = nb2.predict(X2_test_final)
nb2_proba_nb = nb2.predict_proba(X2_test_final)[:, 1]
print(nb2_pred)

ydata = pd.DataFrame()
ydata['y2_test'] = pd.DataFrame(y2_test)
ydata['nb2_pred'] = pd.DataFrame(nb2_pred)
ydata.head()

"""Model 2: Decision Tree

Split Data 90:10
"""

# Resample
tree1 = DecisionTreeClassifier(random_state=42, max_depth=5)
tree1.fit(X1_resampled, y1_resampled)

# Testing
tree1_pred = tree1.predict(X1_test_final)
tree1_proba_nb = tree1.predict_proba(X1_test_final)[:, 1]
print(tree1_pred)

"""Split Data 80:20"""

# Resample
tree2 = DecisionTreeClassifier(random_state=42)
tree2.fit(X2_resampled, y2_resampled)

# Testing
tree2_pred = tree2.predict(X2_test_final)
tree2_proba_nb = tree2.predict_proba(X2_test_final)[:, 1]
print(tree2_pred)

"""# Model Evaluation

Model 1: Naive Bayes

Split Data 90:10
"""

# Tampilkan metrik evaluasi
print("- Naive Bayes Evaluation -")
print("\nClassification Report:\n", classification_report(y1_test, nb1_pred))
print("\n Score roc-auc", roc_auc_score(y1_test, nb1_proba_nb))

cm = confusion_matrix(y1_test, nb1_pred)

plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
                xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""Split Data 80:20"""

print("- Naive Bayes Evaluation -")
print(classification_report(y2_test, nb2_pred))
print("Score roc-auc: ", roc_auc_score(y2_test, nb2_proba_nb))

ConfusionMatrixDisplay.from_predictions(y2_test, nb2_pred)

"""Model 2: Decision Tree

Split Data 90:10
"""

print("- Decision Tree Evaluation -")
print(classification_report(y1_test, tree1_pred))
print("Score roc-auc: ", roc_auc_score(y1_test, tree1_proba_nb))

ConfusionMatrixDisplay.from_predictions(y1_test, tree1_pred)

print("\n=== Rules ===")
tree_rules = export_text(tree1, feature_names=list(X.columns))
print(tree_rules)

"""Split Data 80:20"""

print("- Decision Tree Evaluation -")
print(classification_report(y2_test, tree2_pred))
print("Score roc-auc: ", roc_auc_score(y2_test, tree2_proba_nb))

ConfusionMatrixDisplay.from_predictions(y2_test, tree2_pred)

print("\n=== Rules ===")
tree_rules = export_text(tree2, feature_names=list(X.columns))
print(tree_rules)

"""Metrik Evaluasi (Kelas 1 (Play Golf))

90:10
Metrik          NB              DT
Precision       0.24            0.24
Recall          0.58            0.56
F1-score        0.34            0.34
AUC-ROC         0.63            0.66

80:20
Metrik          NB              DT
Precision       0.25            0.26
Recall          0.58            0.20
F1-score        0.35            0.22
AUC-ROC         0.63            0.58

Pengujian model dilakukan menggunakan 2 skenario pembagian data training & testing, yaitu skenario 1: 90:10, dan skenario 2: 80:20

- Skenario 1: 90:10, NB unggul di recall, DT unggul di AUC-ROC

- Skenario 2: 80:20, NB unggul di recall, F1-score, AUC-ROC, DT unggul di precision (selisih 0.1)

Kesimpulan:
Naive Bayes menunjukkan performa keseluruhan yang lebih baik untuk imbalanced data.

Naive Bayes unggul dalam metrik Recall. Artinya, Naive Bayes lebih baik dalam menangkap orang yang berpotensi bermain golf.

Test New Data
"""

new_data = [[1, 2.9, 49.0, 0, 0.74, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]]

predict_data = nb2.predict(new_data)
print("Predict Result: ", predict_data)